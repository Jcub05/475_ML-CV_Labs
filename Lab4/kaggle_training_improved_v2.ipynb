{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC 475 Lab 4: CLIP Training on Kaggle (IMPROVED)\n",
    "\n",
    "**Optimized with better hyperparameters and 5x more data!**\n",
    "\n",
    "## Key Improvements:\n",
    "- \u2705 Uses ALL 5 captions per image (~400K samples vs ~82K)\n",
    "- \u2705 Lower learning rate (5e-5 vs 1e-4) to prevent overfitting\n",
    "- \u2705 Higher weight decay (0.05 vs 1e-4) for better regularization\n",
    "- \u2705 GPU-optimized Recall@K calculation\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f Before Running:\n",
    "\n",
    "1. **Add datasets**: `jeffaudi/coco-2014-dataset-for-yolov3` + `jcube05/elec-475-lab4`\n",
    "2. **Enable GPU**: T4 or P100\n",
    "3. **Enable Internet**: ON\n",
    "4. **Click \"Save Version\" \u2192 \"Save & Run All (Commit)\"**\n",
    "5. Close your laptop! \ud83d\udca4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Kaggle: {'KAGGLE_KERNEL_RUN_TYPE' in os.environ}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip install -q transformers torch torchvision tqdm pillow matplotlib\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repository & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Force fresh clone\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('475_ML-CV_Labs'):\n",
    "    shutil.rmtree('475_ML-CV_Labs')\n",
    "    print(\"\u2713 Removed old repo\")\n",
    "\n",
    "!git clone https://github.com/Jcub05/475_ML-CV_Labs.git\n",
    "os.chdir('475_ML-CV_Labs/Lab4')\n",
    "print(f\"\u2713 Fresh clone complete\\nDirectory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kaggle-optimized files\n",
    "import shutil\n",
    "\n",
    "# 1. Use Kaggle-compatible dataset loader (handles missing images + ALL 5 captions)\n",
    "shutil.copy('dataset.py', 'dataset_original.py')\n",
    "shutil.copy('dataset_kaggle.py', 'dataset.py')\n",
    "print(\"\u2713 Using Kaggle-compatible dataset loader (ALL 5 captions per image)\")\n",
    "\n",
    "# 2. Use GPU-optimized metrics (100x faster Recall@K)\n",
    "shutil.copy('metrics.py', 'metrics_original.py')\n",
    "shutil.copy('metrics_kaggle.py', 'metrics.py')\n",
    "print(\"\u2713 Using GPU-optimized metrics\")\n",
    "\n",
    "# Verify\n",
    "with open('dataset.py', 'r') as f:\n",
    "    if 'img_path.exists()' in f.read():\n",
    "        print(\"\u2713 Dataset loader verified\")\n",
    "    else:\n",
    "        print(\"\u274c WARNING: Dataset loader not updated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure for Kaggle (IMPROVED HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle config with improved hyperparameters\n",
    "from pathlib import Path\n",
    "\n",
    "if os.path.exists('config.py'):\n",
    "    os.remove('config.py')\n",
    "\n",
    "config_code = '''\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    is_kaggle: bool = True\n",
    "    data_root: str = \"/kaggle/input/coco-2014-dataset-for-yolov3/coco2014\"\n",
    "    text_embeddings_path: str = \"/kaggle/input/elec-475-lab4\"\n",
    "    train_images_dir: str = \"images/train2014\"\n",
    "    val_images_dir: str = \"images/val2014\"\n",
    "    train_captions_file: str = \"annotations/instances_train2014.json\"\n",
    "    val_captions_file: str = \"annotations/instances_val2014.json\"\n",
    "    checkpoint_dir: str = \"checkpoints\"\n",
    "    results_dir: str = \"results\"\n",
    "    embed_dim: int = 512\n",
    "    image_size: int = 224\n",
    "    pretrained_resnet: bool = True\n",
    "    clip_mean: tuple = (0.48145466, 0.4578275, 0.40821073)\n",
    "    clip_std: tuple = (0.26862954, 0.26130258, 0.27577711)\n",
    "    clip_model_name: str = \"openai/clip-vit-base-patch32\"\n",
    "    batch_size: int = 64\n",
    "    num_epochs: int = 10\n",
    "    learning_rate: float = 5e-5  # IMPROVED: Reduced from 1e-4 to prevent overfitting\n",
    "    weight_decay: float = 0.05   # IMPROVED: Increased from 1e-4 for better regularization\n",
    "    temperature: float = 0.07\n",
    "    use_scheduler: bool = True\n",
    "    scheduler_type: str = \"cosine\"\n",
    "    optimizer_type: str = \"adamw\"\n",
    "    beta1: float = 0.9\n",
    "    beta2: float = 0.999\n",
    "    eps: float = 1e-8\n",
    "    max_grad_norm: float = 1.0\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_workers: int = 2\n",
    "    pin_memory: bool = True\n",
    "    use_amp: bool = True\n",
    "    use_subset: bool = False\n",
    "    subset_size: int = 10000\n",
    "    use_cached_embeddings: bool = True\n",
    "    eval_every_n_epochs: int = 1\n",
    "    save_best_only: bool = False\n",
    "    recall_k_values: list = None\n",
    "    num_visualization_samples: int = 10\n",
    "    save_visualizations: bool = True\n",
    "    log_interval: int = 100\n",
    "    verbose: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.recall_k_values is None:\n",
    "            self.recall_k_values = [1, 5, 10]\n",
    "        self.data_root = Path(self.data_root)\n",
    "        self.train_images_path = self.data_root / self.train_images_dir\n",
    "        self.val_images_path = self.data_root / self.val_images_dir\n",
    "        self.train_captions_path = self.data_root / self.train_captions_file\n",
    "        self.val_captions_path = self.data_root / self.val_captions_file\n",
    "        self.cache_path = Path(self.text_embeddings_path)\n",
    "        self.checkpoint_path = Path(\"/kaggle/working\") / self.checkpoint_dir\n",
    "        self.results_path = Path(\"/kaggle/working\") / self.results_dir\n",
    "    \n",
    "    def create_directories(self):\n",
    "        os.makedirs(self.checkpoint_path, exist_ok=True)\n",
    "        os.makedirs(self.results_path, exist_ok=True)\n",
    "    \n",
    "    def validate_paths(self):\n",
    "        required = [\n",
    "            self.train_images_path,\n",
    "            self.val_images_path,\n",
    "            self.cache_path / \"text_embeddings_train.pt\",\n",
    "            self.cache_path / \"text_embeddings_val.pt\"\n",
    "        ]\n",
    "        missing = [str(p) for p in required if not p.exists()]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(f\"Missing: {missing}\")\n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Config(Kaggle | {self.device} | Batch:{self.batch_size} | Epochs:{self.num_epochs} | LR:{self.learning_rate} | WD:{self.weight_decay})\"\n",
    "\n",
    "def get_config(**kwargs):\n",
    "    config = Config(**kwargs)\n",
    "    config.create_directories()\n",
    "    return config\n",
    "'''\n",
    "\n",
    "with open('config.py', 'w') as f:\n",
    "    f.write(config_code)\n",
    "\n",
    "print(\"\u2713 Kaggle config created with IMPROVED hyperparameters\")\n",
    "print(\"  - Learning rate: 5e-5 (was 1e-4)\")\n",
    "print(\"  - Weight decay: 0.05 (was 1e-4)\")\n",
    "print(\"  - Using ALL 5 captions per image (~400K samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate setup\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(config)\n",
    "print(f\"\\nCheckpoints: {config.checkpoint_path}\")\n",
    "print(f\"Results: {config.results_path}\")\n",
    "print(f\"Text embeddings: {config.cache_path}\")\n",
    "\n",
    "print(f\"\\nValidating paths...\")\n",
    "config.validate_paths()\n",
    "print(\"\u2713 All paths valid!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model\n",
    "\n",
    "**Expected improvements:**\n",
    "- Training on ~400K samples (5 captions \u00d7 82K images) vs ~82K\n",
    "- Lower overfitting due to better hyperparameters\n",
    "- Better Recall@K scores (target: 30-40% vs previous 18-22%)\n",
    "\n",
    "**Estimated time:** ~3-4 hours for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING TRAINING (50% DATASET - MEMORY OPTIMIZED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use 50% of dataset (~200K samples) to reduce memory usage\n",
    "!python train.py --num_epochs 10 --batch_size 64 --use_subset --subset_size 200000\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model (Recall@K)\n",
    "\n",
    "**Note:** Recall@K is now computed separately to avoid memory issues during training.\n",
    "\n",
    "**Estimated time:** ~5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPUTING RECALL@K METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!python evaluate.py --checkpoint /kaggle/working/checkpoints/best_model.pth\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OUTPUT FILES\")\n",
    "print(\"=\" * 80)\n",
    "!ls -lhR /kaggle/working/\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Click 'Output' tab at top\n",
    "2. Download all files\n",
    "3. Extract on your computer\n",
    "\n",
    "Key files:\n",
    "  - checkpoints/best_model.pth\n",
    "  - checkpoints/training.log\n",
    "  - results/training_curves.png\n",
    "  - results/final_metrics.json\n",
    "  \n",
    "Expected Recall@K improvements:\n",
    "  - Image\u2192Text R@10: 30-40% (was 18-22%)\n",
    "  - Text\u2192Image R@10: 30-40% (was 18-22%)\n",
    "\"\"\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \u2705 Done!\n",
    "\n",
    "**What changed:**\n",
    "- 5x more training data (all captions)\n",
    "- Better hyperparameters (lower LR, higher WD)\n",
    "- Should see much better Recall@K!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}