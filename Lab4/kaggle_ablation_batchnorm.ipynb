{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC 475 Lab 4: CLIP Ablation Study - BatchNorm Model\n",
    "\n",
    "**Training the BatchNorm variant for ablation study**\n",
    "\n",
    "## Model Configuration:\n",
    "- \u2705 BatchNorm in projection head\n",
    "- \u274c No Dropout\n",
    "- \u274c Standard 2-layer projection\n",
    "- \u274c Fixed temperature\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f Before Running:\n",
    "\n",
    "1. **Add datasets**: `jeffaudi/coco-2014-dataset-for-yolov3` + `jacobbadali2/elec-475-lab4`\n",
    "2. **Enable GPU**: T4 or P100\n",
    "3. **Enable Internet**: ON\n",
    "4. **Click Save Version then Save and Run All**\n",
    "5. Close your laptop! \ud83d\udca4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Kaggle: {'KAGGLE_KERNEL_RUN_TYPE' in os.environ}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip install -q transformers torch torchvision tqdm pillow matplotlib\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repository & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Force fresh clone\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('475_ML-CV_Labs'):\n",
    "    shutil.rmtree('475_ML-CV_Labs')\n",
    "    print(\"\u2713 Removed old repo\")\n",
    "\n",
    "!git clone https://github.com/Jcub05/475_ML-CV_Labs.git\n",
    "os.chdir('475_ML-CV_Labs/Lab4')\n",
    "print(f\"\u2713 Fresh clone complete\\nDirectory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kaggle-optimized files\n",
    "import shutil\n",
    "\n",
    "# 1. Use Kaggle-compatible dataset loader\n",
    "shutil.copy('dataset.py', 'dataset_original.py')\n",
    "shutil.copy('dataset_kaggle.py', 'dataset.py')\n",
    "print(\"\u2713 Using Kaggle-compatible dataset loader\")\n",
    "\n",
    "# 2. Use GPU-optimized metrics\n",
    "shutil.copy('metrics.py', 'metrics_original.py')\n",
    "shutil.copy('metrics_kaggle.py', 'metrics.py')\n",
    "print(\"\u2713 Using GPU-optimized metrics\")\n",
    "\n",
    "# Verify\n",
    "with open('dataset.py', 'r') as f:\n",
    "    if 'img_path.exists()' in f.read():\n",
    "        print(\"\u2713 Dataset loader verified\")\n",
    "    else:\n",
    "        print(\"\u274c WARNING: Dataset loader not updated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Ablation Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified training script for the BatchNorm ablation model\n",
    "ablation_script = '''#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Train BatchNorm ablation model for CLIP fine-tuning.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "from config import get_config\n",
    "from dataset import create_dataloaders\n",
    "from model_modified import create_modified_model\n",
    "from loss import InfoNCELossWithMetrics\n",
    "from utils import set_seed, get_device, Logger\n",
    "from train import train_epoch, validate_epoch\n",
    "from utils import AverageMeter, Timer, save_checkpoint, format_time, plot_training_curves\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "def main():\n",
    "    # Setup\n",
    "    set_seed(42)\n",
    "    device = get_device()\n",
    "    \n",
    "    # Get config with 50% dataset\n",
    "    config = get_config(\n",
    "        use_subset=True,\n",
    "        subset_size=200000,\n",
    "        batch_size=64,\n",
    "        num_epochs=10,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.05\n",
    "    )\n",
    "    \n",
    "    # Update checkpoint directory for ablation\n",
    "    config.checkpoint_path = config.checkpoint_path.parent / \"ablation_batchnorm\"\n",
    "    config.results_path = config.results_path.parent / \"ablation_batchnorm_results\"\n",
    "    config.create_directories()\n",
    "    \n",
    "    # Logger\n",
    "    log_file = config.results_path / \"training_log.txt\"\n",
    "    logger = Logger(log_file=log_file, verbose=config.verbose)\n",
    "    \n",
    "    logger.log(\"=\" * 80)\n",
    "    logger.log(\"CLIP Ablation Study - BatchNorm Model\")\n",
    "    logger.log(\"=\" * 80)\n",
    "    logger.log(\"Configuration: BatchNorm in projection head\")\n",
    "    logger.log(str(config))\n",
    "    \n",
    "    # Create dataloaders\n",
    "    logger.log(\"\\\\nCreating dataloaders...\")\n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        data_root=config.data_root,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_memory,\n",
    "        use_cached_embeddings=config.use_cached_embeddings,\n",
    "        use_subset=config.use_subset,\n",
    "        subset_size=config.subset_size\n",
    "    )\n",
    "    \n",
    "    # Load text encoder\n",
    "    logger.log(\"\\\\nLoading text encoder...\")\n",
    "    text_encoder = CLIPTextModel.from_pretrained(config.clip_model_name)\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(config.clip_model_name)\n",
    "    text_encoder = text_encoder.to(device)\n",
    "    text_encoder.eval()\n",
    "    \n",
    "    # Create BatchNorm model\n",
    "    logger.log(\"\\\\nCreating BatchNorm ablation model...\")\n",
    "    model = create_modified_model(\n",
    "        text_encoder=text_encoder,\n",
    "        tokenizer=tokenizer,\n",
    "        embed_dim=config.embed_dim,\n",
    "        use_batchnorm=True,  # ABLATION: BatchNorm enabled\n",
    "        use_dropout=False,\n",
    "        deeper_projection=False,\n",
    "        learnable_temperature=False\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    from model import count_parameters\n",
    "    trainable, total = count_parameters(model)\n",
    "    logger.log(f\"Model parameters: {trainable:,} trainable / {total:,} total\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = InfoNCELossWithMetrics(\n",
    "        temperature=config.temperature,\n",
    "        learnable_temperature=False\n",
    "    )\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay,\n",
    "        betas=(config.beta1, config.beta2),\n",
    "        eps=config.eps\n",
    "    )\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config.num_epochs,\n",
    "        eta_min=config.learning_rate * 0.01\n",
    "    )\n",
    "    \n",
    "    # Mixed precision\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float(\\'inf\\')\n",
    "    \n",
    "    # Training loop\n",
    "    logger.log(\"\\\\n\" + \"=\" * 80)\n",
    "    logger.log(\"Starting Training\")\n",
    "    logger.log(\"=\" * 80 + \"\\\\n\")\n",
    "    \n",
    "    total_timer = Timer()\n",
    "    total_timer.start()\n",
    "    \n",
    "    for epoch in range(1, config.num_epochs + 1):\n",
    "        epoch_timer = Timer()\n",
    "        epoch_timer.start()\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer,\n",
    "            device, epoch, config, logger, scaler\n",
    "        )\n",
    "        train_losses.append(train_metrics[\\'loss\\'])\n",
    "        \n",
    "        # Validate\n",
    "        if epoch % config.eval_every_n_epochs == 0:\n",
    "            val_metrics = validate_epoch(\n",
    "                model, val_loader, criterion, device, config, logger\n",
    "            )\n",
    "            val_losses.append(val_metrics[\\'loss\\'])\n",
    "            \n",
    "            # Check if best model\n",
    "            current_loss = val_metrics[\\'loss\\']\n",
    "            is_best = current_loss < best_val_loss\n",
    "            \n",
    "            if is_best:\n",
    "                best_val_loss = current_loss\n",
    "                logger.log(f\"\u2713 New best model! Val Loss: {best_val_loss:.4f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint_name = f\"checkpoint_epoch_{epoch}.pth\" if not config.save_best_only else \"best_model.pth\"\n",
    "            checkpoint_path = config.checkpoint_path / checkpoint_name\n",
    "            \n",
    "            save_checkpoint(\n",
    "                model, optimizer, epoch, val_metrics[\\'loss\\'],\n",
    "                val_metrics, checkpoint_path, is_best\n",
    "            )\n",
    "            logger.log(f\"Checkpoint saved: {checkpoint_path.name}\")\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log epoch summary\n",
    "        epoch_time = epoch_timer.stop()\n",
    "        logger.log(f\"\\\\nEpoch {epoch} completed in {format_time(epoch_time)}\")\n",
    "        logger.log(f\"Learning rate: {optimizer.param_groups[0][\\'lr\\']:.6f}\\\\n\")\n",
    "    \n",
    "    # Training complete\n",
    "    total_time = total_timer.stop()\n",
    "    logger.log(\"\\\\n\" + \"=\" * 80)\n",
    "    logger.log(\"Training Complete!\")\n",
    "    logger.log(\"=\" * 80)\n",
    "    logger.log(f\"Total training time: {format_time(total_time)}\")\n",
    "    logger.log(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plot_path = config.results_path / \"training_curves.png\"\n",
    "    plot_training_curves(train_losses, val_losses, plot_path)\n",
    "    logger.log(f\"Training curves saved: {plot_path}\")\n",
    "    \n",
    "    logger.log(\"\\\\nAll done! Run evaluate.py to compute Recall@K metrics.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('train_ablation_batchnorm.py', 'w') as f:\n",
    "    f.write(ablation_script)\n",
    "\n",
    "print(\"\u2713 Created ablation training script: train_ablation_batchnorm.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate setup\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(config)\n",
    "print(f\"\\nCheckpoints: {config.checkpoint_path}\")\n",
    "print(f\"Results: {config.results_path}\")\n",
    "print(f\"Text embeddings: {config.cache_path}\")\n",
    "\n",
    "print(f\"\\nValidating paths...\")\n",
    "config.validate_paths()\n",
    "print(\"\u2713 All paths valid!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train BatchNorm Ablation Model\n",
    "\n",
    "**Model:** BatchNorm in projection head  \n",
    "**Dataset:** 50% (~200K samples)  \n",
    "**Estimated time:** ~1.5-2 hours for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING ABLATION TRAINING - BATCHNORM MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!python train_ablation_batchnorm.py\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model (Recall@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPUTING RECALL@K METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!python evaluate.py --checkpoint /kaggle/working/ablation_batchnorm/best_model.pth\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OUTPUT FILES\")\n",
    "print(\"=\" * 80)\n",
    "!ls -lhR /kaggle/working/\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Click 'Output' tab at top\n",
    "2. Download all files\n",
    "3. Extract on your computer\n",
    "\n",
    "Key files:\n",
    "  - ablation_batchnorm/best_model.pth\n",
    "  - ablation_batchnorm_results/training_log.txt\n",
    "  - ablation_batchnorm_results/training_curves.png\n",
    "  - results/recall_metrics.json\n",
    "  \n",
    "Compare these results with your baseline model!\n",
    "\"\"\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \u2705 Done!\n",
    "\n",
    "**BatchNorm Ablation Model Trained**\n",
    "\n",
    "Compare with baseline to see if BatchNorm improves performance!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}