{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC 475 Lab 4: CLIP Training on Kaggle\n",
    "\n",
    "**Simple, clean training notebook - no inline code modifications!**\n",
    "\n",
    "Trains baseline CLIP model for 10 epochs (~3-4 hours)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Before Running:\n",
    "\n",
    "1. **Add datasets**: `jeffaudi/coco-2014-dataset-for-yolov3` + `jcube05/elec-475-lab4`\n",
    "2. **Enable GPU**: T4 or P100\n",
    "3. **Enable Internet**: ON\n",
    "4. **Click \"Run All\"** and close your laptop! üí§\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Kaggle: {'KAGGLE_KERNEL_RUN_TYPE' in os.environ}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip install -q transformers torch torchvision tqdm pillow matplotlib\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repository & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Clone repo\n",
    "!git clone https://github.com/Jcub05/475_ML-CV_Labs.git\n",
    "os.chdir('475_ML-CV_Labs/Lab4')\n",
    "print(f\"‚úì Repository cloned\\nDirectory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kaggle-compatible dataset loader\n",
    "import shutil\n",
    "\n",
    "# Backup original and use Kaggle version\n",
    "shutil.copy('dataset.py', 'dataset_original.py')\n",
    "shutil.copy('dataset_kaggle.py', 'dataset.py')\n",
    "\n",
    "print(\"‚úì Using Kaggle-compatible dataset loader (dataset_kaggle.py)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle config\n",
    "from pathlib import Path\n",
    "\n",
    "if os.path.exists('config.py'):\n",
    "    os.remove('config.py')\n",
    "\n",
    "config_code = '''\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    is_kaggle: bool = True\n",
    "    data_root: str = \"/kaggle/input/coco-2014-dataset-for-yolov3/coco2014\"\n",
    "    text_embeddings_path: str = \"/kaggle/input/elec-475-lab4\"\n",
    "    train_images_dir: str = \"images/train2014\"\n",
    "    val_images_dir: str = \"images/val2014\"\n",
    "    train_captions_file: str = \"annotations/instances_train2014.json\"\n",
    "    val_captions_file: str = \"annotations/instances_val2014.json\"\n",
    "    checkpoint_dir: str = \"checkpoints\"\n",
    "    results_dir: str = \"results\"\n",
    "    embed_dim: int = 512\n",
    "    image_size: int = 224\n",
    "    pretrained_resnet: bool = True\n",
    "    clip_mean: tuple = (0.48145466, 0.4578275, 0.40821073)\n",
    "    clip_std: tuple = (0.26862954, 0.26130258, 0.27577711)\n",
    "    clip_model_name: str = \"openai/clip-vit-base-patch32\"\n",
    "    batch_size: int = 64\n",
    "    num_epochs: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    temperature: float = 0.07\n",
    "    use_scheduler: bool = True\n",
    "    scheduler_type: str = \"cosine\"\n",
    "    optimizer_type: str = \"adamw\"\n",
    "    beta1: float = 0.9\n",
    "    beta2: float = 0.999\n",
    "    eps: float = 1e-8\n",
    "    max_grad_norm: float = 1.0\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_workers: int = 2\n",
    "    pin_memory: bool = True\n",
    "    use_amp: bool = True\n",
    "    use_subset: bool = False\n",
    "    subset_size: int = 10000\n",
    "    use_cached_embeddings: bool = True\n",
    "    eval_every_n_epochs: int = 1\n",
    "    save_best_only: bool = False\n",
    "    recall_k_values: list = None\n",
    "    num_visualization_samples: int = 10\n",
    "    save_visualizations: bool = True\n",
    "    log_interval: int = 100\n",
    "    verbose: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.recall_k_values is None:\n",
    "            self.recall_k_values = [1, 5, 10]\n",
    "        self.data_root = Path(self.data_root)\n",
    "        self.train_images_path = self.data_root / self.train_images_dir\n",
    "        self.val_images_path = self.data_root / self.val_images_dir\n",
    "        self.train_captions_path = self.data_root / self.train_captions_file\n",
    "        self.val_captions_path = self.data_root / self.val_captions_file\n",
    "        self.cache_path = Path(self.text_embeddings_path)\n",
    "        self.checkpoint_path = Path(\"/kaggle/working\") / self.checkpoint_dir\n",
    "        self.results_path = Path(\"/kaggle/working\") / self.results_dir\n",
    "    \n",
    "    def create_directories(self):\n",
    "        os.makedirs(self.checkpoint_path, exist_ok=True)\n",
    "        os.makedirs(self.results_path, exist_ok=True)\n",
    "    \n",
    "    def validate_paths(self):\n",
    "        required = [\n",
    "            self.train_images_path,\n",
    "            self.val_images_path,\n",
    "            self.cache_path / \"text_embeddings_train.pt\",\n",
    "            self.cache_path / \"text_embeddings_val.pt\"\n",
    "        ]\n",
    "        missing = [str(p) for p in required if not p.exists()]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(f\"Missing: {missing}\")\n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Config(Kaggle | {self.device} | Batch:{self.batch_size} | Epochs:{self.num_epochs})\"\n",
    "\n",
    "def get_config(**kwargs):\n",
    "    config = Config(**kwargs)\n",
    "    config.create_directories()\n",
    "    return config\n",
    "'''\n",
    "\n",
    "with open('config.py', 'w') as f:\n",
    "    f.write(config_code)\n",
    "\n",
    "print(\"‚úì Kaggle config created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate setup\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(config)\n",
    "print(f\"\\nCheckpoints: {config.checkpoint_path}\")\n",
    "print(f\"Results: {config.results_path}\")\n",
    "print(f\"Text embeddings: {config.cache_path}\")\n",
    "\n",
    "print(f\"\\nValidating paths...\")\n",
    "config.validate_paths()\n",
    "print(\"‚úì All paths valid!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model\n",
    "\n",
    "Training 10 epochs with batch size 64.\n",
    "\n",
    "Checkpoints saved to `/kaggle/working/checkpoints/` every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!python train.py --num_epochs 10 --batch_size 64\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OUTPUT FILES\")\n",
    "print(\"=\" * 80)\n",
    "!ls -lhR /kaggle/working/\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Click 'Output' tab at top\n",
    "2. Download all files\n",
    "3. Extract on your computer\n",
    "\n",
    "Key files:\n",
    "  - checkpoints/best_model.pth\n",
    "  - checkpoints/training.log\n",
    "  - results/training_curves.png\n",
    "\"\"\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Done!\n",
    "\n",
    "Download outputs and use for your lab report.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
