# ELEC 475 Lab 3 - Testing Commands
# All commands should be run from the Lab 3 directory
# Make sure you have completed training and have checkpoint files in ./checkpoints/

# ============================================================================
# ULTRA-COMPACT MODEL (475K parameters)
# ============================================================================

# Test baseline model (No KD)
python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_none.pth --visualize --num_vis 10 --save_dir ./results

# Test response-based KD model
python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_response.pth --visualize --num_vis 10 --save_dir ./results

# Test feature-based KD model
python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_feature.pth --visualize --num_vis 10 --save_dir ./results

# ============================================================================
# STANDARD MODEL (3.4M parameters)
# ============================================================================

# Test baseline model (No KD)
python test.py --model standard --checkpoint ./checkpoints/best_model_standard_none.pth --visualize --num_vis 10 --save_dir ./results

# Test response-based KD model
python test.py --model standard --checkpoint ./checkpoints/best_model_standard_response.pth --visualize --num_vis 10 --save_dir ./results

# Test feature-based KD model
python test.py --model standard --checkpoint ./checkpoints/best_model_standard_feature.pth --visualize --num_vis 10 --save_dir ./results

# ============================================================================
# GENERATE COMPARISON TABLE (After all testing is complete)
# ============================================================================

# Generate comprehensive comparison table with analysis
python generate_comparison_table.py --results_dir ./results --checkpoints_dir ./checkpoints --save_latex --output comparison_table.tex

# ============================================================================
# TESTING OUTPUT FILES
# ============================================================================
# For each test run, the following files will be generated in ./results/:
#   - results_{model}_{kd_mode}.txt              (detailed results with per-class IoU)
#   - results_{model}_{kd_mode}.pkl              (results in pickle format)
#   - visualizations_{model}_{kd_mode}/          (folder with segmentation overlays)
#   - visualizations_{model}_{kd_mode}/class_legend.png (color legend)

# After running generate_comparison_table.py:
#   - comparison_table.txt                       (human-readable comparison)
#   - comparison_table.tex                       (LaTeX format for report)

# ============================================================================
# OPTIONAL: TEST WITHOUT VISUALIZATIONS (faster)
# ============================================================================
# If you just want mIoU scores without generating visualizations:
# python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_none.pth --save_dir ./results

# ============================================================================
# OPTIONAL: GENERATE MORE/FEWER VISUALIZATIONS
# ============================================================================
# Generate 20 visualizations instead of 10:
# python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_none.pth --visualize --num_vis 20 --save_dir ./results

# Generate only 5 visualizations:
# python test.py --model ultracompact --checkpoint ./checkpoints/best_model_ultracompact_none.pth --visualize --num_vis 5 --save_dir ./results

# ============================================================================
# TEST PRETRAINED FCN-RESNET50 (Step 1 baseline)
# ============================================================================
# Test the pretrained teacher model for comparison:
python test_pretrained_fcn.py

# ============================================================================
# NOTES
# ============================================================================
# - Testing is much faster than training (~5-10 minutes per model)
# - Visualizations show: Original Image | Ground Truth | Prediction
# - Per-class IoU is automatically calculated and saved
# - Score is calculated as: 4 Ã— mIoU / (1 + parameters_in_millions)
# - Select 3-5 good visualizations and 2-3 failure cases for your report
